:imagesdir: img/additional_info_customize_input

# Additional Info: How customers can customize this QS for their own dataset? What steps user needs to take to achieve it.

The pipeline can easily be adopt to your own data format. For that the first ETL job has to be adjusted to map the incoming data to the internal meter data lake schema. The next steps demonstrate how this can be achieved.

The first step in the ETL workflow transforms the raw data in the landing zone to cleaned data in the Clean Zone. This step is also responsible for mapping the inbound data to the internal data scheme which the following steps expect.
To change this steps, the AWS Glue job can be edited directly in the web editor.

1. Navigate to the AWS Glue Job console
image:1_edit_etl_job.png[AWS Glue Job console]

2. Select the 'transform_raw_to_clean-us-east-1' job
image:2_edit_etl_job.png[AWS Glue Job console]

3. Open script editor and start editing the input mapping
image:3_open_editor.png[Open editor]

4. To adopt a different input format look for the 'ApplyMapping' call and adjust it to your needs  to reflect your custom input format. Currently, the internal model works with the following schema:

[cols="1,1,1,1", options="header"]
.Schema
|===
|Field
|Type
|Mandatory
|Format

|meter_id| String| X|
|reading_value| double| X|
|reading_type| String| X|
|reading_date_time| Timestamp| X|
|date_str| String|X| yyyyMMdd
|obis_code| String| |
|week_of_year| int| |
|month| int| |
|year| int| |
|hour| int| |
|minute| int| |
|===